{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor and Variable\n",
    "这是 PyTorch 基础的第二课，通过本次课程，你能够学会如何像使用 NumPy 一样使用 PyTorch，了解到 PyTorch 中的基本元素 Tensor 和 Variable 及其操作方式。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 把 PyTorch 当做 NumPy 用\n",
    "PyTorch 的官方介绍是一个拥有强力GPU加速的张量和动态构建网络的库，其主要构件是张量，所以我们可以把 PyTorch 当做 NumPy 来用，PyTorch 的很多操作好 NumPy 都是类似的，但是因为其能够在 GPU 上运行，所以有着比 NumPy 快很多倍的速度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个 numpy ndarray\n",
    "numpy_tensor = np.random.randn(10, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以使用下面两种方式将numpy的ndarray转换到tensor上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pytorch_tensor1 = torch.Tensor(numpy_tensor)\n",
    "pytorch_tensor2 = torch.from_numpy(numpy_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用以上两种方法进行转换的时候，会直接将 NumPy ndarray 的数据类型转换为对应的 PyTorch Tensor 数据类型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同时我们也可以使用下面的方法将 pytorch tensor 转换为 numpy ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 如果 pytorch tensor 在 cpu 上\n",
    "numpy_array = pytorch_tensor1.numpy()\n",
    "\n",
    "# 如果 pytorch tensor 在 gpu 上\n",
    "numpy_array = pytorch_tensor1.cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "需要注意 GPU 上的 Tensor 不能直接转换为 NumPy ndarray，需要使用`.cpu()`先将 GPU 上的 Tensor 转到 CPU 上"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch Tensor 使用 GPU 加速\n",
    "\n",
    "我们可以使用以下两种方式将 Tensor 放到 GPU 上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "torch.cuda.FloatTensor is not enabled.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-4516e79da28b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# 第二种方式更简单，推荐使用\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mgpu_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 将 tensor 放到第一个 GPU 上\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mgpu_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 将 tensor 放到第二个 GPU 上\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: torch.cuda.FloatTensor is not enabled."
     ]
    }
   ],
   "source": [
    "# 第一种方式是定义 cuda 数据类型\n",
    "dtype = torch.cuda.FloatTensor # 定义默认 GPU 的 数据类型\n",
    "gpu_tensor = torch.randn(10, 20).type(dtype)\n",
    "\n",
    "# 第二种方式更简单，推荐使用\n",
    "gpu_tensor = torch.randn(10, 20).cuda(0) # 将 tensor 放到第一个 GPU 上\n",
    "gpu_tensor = torch.randn(10, 20).cuda(1) # 将 tensor 放到第二个 GPU 上"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用第一种方式将 tensor 放到 GPU 上的时候会将数据类型转换成定义的类型，而是用第二种方式能够直接将 tensor 放到 GPU 上，类型跟之前保持一致\n",
    "\n",
    "推荐在定义 tensor 的时候就明确数据类型，然后直接使用第二种方法将 tensor 放到 GPU 上"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "而将 tensor 放回 CPU 的操作非常简单"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cpu_tensor = gpu_tensor.cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们也能够访问到 Tensor 的一些属性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 20])\n",
      "torch.Size([10, 20])\n"
     ]
    }
   ],
   "source": [
    "# 可以通过下面两种方式得到 tensor 的大小\n",
    "print(pytorch_tensor1.shape)\n",
    "print(pytorch_tensor1.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "# 得到 tensor 的数据类型\n",
    "print(pytorch_tensor1.type())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "# 得到 tensor 的维度\n",
    "print(pytorch_tensor1.dim())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "# 得到 tensor 的所有元素个数\n",
    "print(pytorch_tensor1.numel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**小练习**\n",
    "\n",
    "查阅以下[文档](http://pytorch.org/docs/0.3.0/tensors.html)了解 tensor 的数据类型，创建一个 float64、大小是 3 x 2、随机初始化的 tensor，将其转化为 numpy 的 ndarray，输出其数据类型\n",
    "\n",
    "参考输出: float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n"
     ]
    }
   ],
   "source": [
    "# 答案\n",
    "x = torch.randn(3, 2)\n",
    "x = x.type(torch.DoubleTensor)\n",
    "x_array = x.numpy()\n",
    "print(x_array.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor的操作\n",
    "Tensor 操作中的 api 和 NumPy 非常相似，如果你熟悉 NumPy 中的操作，那么 tensor 基本是一致的，下面我们来列举其中的一些操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  1.],\n",
      "        [ 1.,  1.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2, 2)\n",
    "print(x) # 这是一个float tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "print(x.type())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1,  1],\n",
      "        [ 1,  1]])\n"
     ]
    }
   ],
   "source": [
    "# 将其转化为整形\n",
    "x = x.long()\n",
    "# x = x.type(torch.LongTensor)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  1.],\n",
      "        [ 1.,  1.]])\n"
     ]
    }
   ],
   "source": [
    "# 再将其转回 float\n",
    "x = x.float()\n",
    "# x = x.type(torch.FloatTensor)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.1432,  0.3221, -0.8055],\n",
      "        [ 0.9240,  0.5129, -0.6421],\n",
      "        [ 0.8475,  1.0624,  0.7963],\n",
      "        [ 1.7084, -1.1395,  1.1297]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(4, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 沿着行取最大值\n",
    "max_value, max_idx = torch.max(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.1432,  0.9240,  1.0624,  1.7084])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 每一行的最大值\n",
    "max_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  0,  1,  0])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 每一行最大值的下标\n",
    "max_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.6597,  0.7948,  2.7062,  1.6986])\n"
     ]
    }
   ],
   "source": [
    "# 沿着行对 x 求和\n",
    "sum_x = torch.sum(x, dim=1)\n",
    "print(sum_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3])\n",
      "torch.Size([1, 4, 3])\n"
     ]
    }
   ],
   "source": [
    "# 增加维度或者减少维度\n",
    "print(x.shape)\n",
    "x = x.unsqueeze(0) # 在第一维增加\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 4, 3])\n"
     ]
    }
   ],
   "source": [
    "x = x.unsqueeze(1) # 在第二维增加\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 3])\n"
     ]
    }
   ],
   "source": [
    "x = x.squeeze(0) # 减少第一维\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3])\n"
     ]
    }
   ],
   "source": [
    "x = x.squeeze() # 将 tensor 中所有的一维全部都去掉\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4, 5])\n",
      "torch.Size([4, 3, 5])\n",
      "torch.Size([5, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, 4, 5)\n",
    "print(x.shape)\n",
    "\n",
    "# 使用permute和transpose进行维度交换\n",
    "x = x.permute(1, 0, 2) # permute 可以重新排列 tensor 的维度\n",
    "print(x.shape)\n",
    "\n",
    "x = x.transpose(0, 2)  # transpose 交换 tensor 中的两个维度\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4, 5])\n",
      "torch.Size([12, 5])\n",
      "torch.Size([3, 20])\n"
     ]
    }
   ],
   "source": [
    "# 使用 view 对 tensor 进行 reshape\n",
    "x = torch.randn(3, 4, 5)\n",
    "print(x.shape)\n",
    "\n",
    "x = x.view(-1, 5) # -1 表示任意的大小，5 表示第二维变成 5\n",
    "print(x.shape)\n",
    "\n",
    "x = x.view(3, 20) # 重新 reshape 成 (3, 20) 的大小\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = torch.randn(3, 4)\n",
    "y = torch.randn(3, 4)\n",
    "\n",
    "# 两个 tensor 求和\n",
    "z = x + y\n",
    "# z = torch.add(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "另外，pytorch中大多数的操作都支持 inplace 操作，也就是可以直接对 tensor 进行操作而不需要另外开辟内存空间，方式非常简单，一般都是在操作的符号后面加`_`，比如"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3])\n",
      "torch.Size([1, 3, 3])\n",
      "torch.Size([3, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(3, 3)\n",
    "print(x.shape)\n",
    "\n",
    "# unsqueeze 进行 inplace\n",
    "x.unsqueeze_(0)\n",
    "print(x.shape)\n",
    "\n",
    "# transpose 进行 inplace\n",
    "x.transpose_(1, 0)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.]])\n",
      "tensor([[ 2.,  2.,  2.],\n",
      "        [ 2.,  2.,  2.],\n",
      "        [ 2.,  2.,  2.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(3, 3)\n",
    "y = torch.ones(3, 3)\n",
    "print(x)\n",
    "\n",
    "# add 进行 inplace\n",
    "x.add_(y)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**小练习**\n",
    "\n",
    "访问[文档](http://pytorch.org/docs/0.3.0/tensors.html)了解 tensor 更多的 api，实现下面的要求\n",
    "\n",
    "创建一个 float32、4 x 4 的全为1的矩阵，将矩阵正中间 2 x 2 的矩阵，全部修改成2\n",
    "\n",
    "参考输出\n",
    "$$\n",
    "\\left[\n",
    "\\begin{matrix}\n",
    "1 & 1 & 1 & 1 \\\\\n",
    "1 & 2 & 2 & 1 \\\\\n",
    "1 & 2 & 2 & 1 \\\\\n",
    "1 & 1 & 1 & 1\n",
    "\\end{matrix}\n",
    "\\right] \\\\\n",
    "[torch.FloatTensor\\ of\\ size\\ 4x4]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1  1  1  1\n",
      " 1  2  2  1\n",
      " 1  2  2  1\n",
      " 1  1  1  1\n",
      "[torch.FloatTensor of size 4x4]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 答案\n",
    "x = torch.ones(4, 4).float()\n",
    "x[1:3, 1:3] = 2\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable\n",
    "tensor 是 PyTorch 中的完美组件，但是构建神经网络还远远不够，我们需要能够构建计算图的 tensor，这就是 Variable。Variable 是对 tensor 的封装，操作和 tensor 是一样的，但是每个 Variabel都有三个属性，Variable 中的 tensor本身`.data`，对应 tensor 的梯度`.grad`以及这个 Variable 是通过什么方式得到的`.grad_fn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 通过下面这种方式导入 Variable\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tensor = torch.randn(10, 5)\n",
    "y_tensor = torch.randn(10, 5)\n",
    "\n",
    "# 将 tensor 变成 Variable\n",
    "x = Variable(x_tensor, requires_grad=True) # 默认 Variable 是不需要求梯度的，所以我们用这个方式申明需要对其进行求梯度\n",
    "y = Variable(y_tensor, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z = torch.sum(x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-11.9023)\n",
      "<SumBackward0 object at 0x0000024A8980C5F8>\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(z.data)\n",
    "print(z.grad_fn)\n",
    "print(z.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面我们打出了 z 中的 tensor 数值，同时通过`grad_fn`知道了其是通过 Sum 这种方式得到的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  1.,  1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.,  1.,  1.]])\n",
      "tensor([[ 1.,  1.,  1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.,  1.,  1.],\n",
      "        [ 1.,  1.,  1.,  1.,  1.]])\n"
     ]
    }
   ],
   "source": [
    "# 求 x 和 y 的梯度\n",
    "z.backward()\n",
    "\n",
    "print(x.grad)\n",
    "print(y.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过`.grad`我们得到了 x 和 y 的梯度，这里我们使用了 PyTorch 提供的自动求导机制，非常方便，下一小节会具体讲自动求导。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**小练习**\n",
    "\n",
    "尝试构建一个函数 $y = x^2 $，然后求 x=2 的导数。\n",
    "\n",
    "参考输出：4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "提示：\n",
    "\n",
    "$y = x^2$的图像如下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nyQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x24a898200f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x = np.arange(-3, 3.01, 0.1)\n",
    "y = x ** 2\n",
    "plt.plot(x, y)\n",
    "plt.plot(2, 4, 'ro')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 4.])\n"
     ]
    }
   ],
   "source": [
    "# 答案\n",
    "x = Variable(torch.FloatTensor([2]), requires_grad=True)\n",
    "y = x ** 2\n",
    "y.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下一次课程我们将会从导数展开，了解 PyTorch 的自动求导机制"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
