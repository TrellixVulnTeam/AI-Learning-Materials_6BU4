{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"lenet.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"metadata":{"id":"K2a_s2Yz2MJu","colab_type":"text"},"cell_type":"markdown","source":["# 卷积神经网络（LeNet）\n","\n","在[“多层感知机的从零开始实现”](../chapter_deep-learning-basics/mlp-scratch.md)一节里我们构造了一个含单隐藏层的多层感知机模型来对Fashion-MNIST数据集中的图像进行分类。每张图像高和宽均是28像素。我们将图像中的像素逐行展开，得到长度为784的向量，并输入进全连接层中。然而，这种分类方法有一定的局限性：\n","\n","1. 图像在同一列邻近的像素在这个向量中可能相距较远。它们构成的模式可能难以被模型识别。\n","2. 对于大尺寸的输入图像，使用全连接层容易造成模型过大。假设输入是高和宽均为1000像素的彩色照片（含三个通道）。即使全连接层输出个数仍是256，该层权重参数的形状是$3,000,000\\times 256$：它占用了大约3GB的内存。这带来过复杂的模型和过高的存储开销。\n","\n","卷积层尝试解决这两个问题。一方面，卷积层保留输入形状，使得图像的像素在高和宽两个方向上的相关性均可能被有效识别。另一方面，卷积层通过滑动窗口将同一卷积核与不同位置的输入重复计算，从而避免参数尺寸过大。\n","\n","卷积神经网络就是含卷积层的网络。本节里我们将介绍一个早期用来识别手写数字图像的卷积神经网络：LeNet [1]。这个名字来源于LeNet论文的第一作者Yann LeCun。LeNet展示了通过梯度下降训练卷积神经网络可以达到手写数字识别在当时最先进的结果。这个奠基性的工作第一次将卷积神经网络推上舞台，为世人所知。\n","\n","## LeNet模型\n","\n","LeNet分为卷积层块和全连接层块两个部分。下面我们分别介绍这两个模块。\n","\n","卷积层块里的基本单位是卷积层后接最大池化层：卷积层用来识别图像里的空间模式，例如线条和物体局部，之后的最大池化层则用来降低卷积层对位置的敏感性。卷积层块由两个这样的基本单位重复堆叠构成。在卷积层块中，每个卷积层都使用$5\\times 5$的窗口，并在输出上使用sigmoid激活函数。第一个卷积层输出通道数为6，第二个卷积层输出通道数则增加到16。这是因为第二个卷积层比第一个卷积层的输入的高和宽要小，所以增加输出通道使两个卷积层的参数尺寸类似。卷积层块的两个最大池化层的窗口形状均为$2\\times 2$，且步幅为2。由于池化窗口与步幅形状相同，池化窗口在输入上每次滑动所覆盖的区域互不重叠。\n","\n","卷积层块的输出形状为（批量大小，通道，高，宽）。当卷积层块的输出传入全连接层块时，全连接层块会将小批量中每个样本变平（flatten）。也就是说，全连接层的输入形状将变成二维，其中第一维为小批量中的样本，第二维为每个样本变平后的向量表示，且向量长度为通道、高和宽的乘积。全连接层块含三个全连接层。它们的输出个数分别是120、84和10。其中10为输出的类别个数。\n","\n","下面我们通过Sequential类来实现LeNet模型。"]},{"metadata":{"id":"faGUoSpv2R7d","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":126},"outputId":"c7945407-eee2-40aa-cf42-038dff4001d3","executionInfo":{"status":"ok","timestamp":1550111866714,"user_tz":-480,"elapsed":58152,"user":{"displayName":"binghao liang","photoUrl":"","userId":"16749033974285927585"}}},"cell_type":"code","source":["!apt-get install -y -qq software-properties-common module-init-tools\n","!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n","!apt-get update -qq 2>&1 > /dev/null\n","!apt-get -y install -qq google-drive-ocamlfuse fuse\n","from google.colab import auth\n","auth.authenticate_user()\n","from oauth2client.client import GoogleCredentials\n","creds = GoogleCredentials.get_application_default()\n","import getpass\n","!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n","vcode = getpass.getpass()\n","!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"],"execution_count":3,"outputs":[{"output_type":"stream","text":["^C\n","Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n","··········\n","Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n","Please enter the verification code: Access token retrieved correctly.\n"],"name":"stdout"}]},{"metadata":{"id":"7UGRIEcC2WGV","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":250},"outputId":"4ac0bac7-61c4-4031-b542-fd8d7c56632b","executionInfo":{"status":"ok","timestamp":1550111884459,"user_tz":-480,"elapsed":9519,"user":{"displayName":"binghao liang","photoUrl":"","userId":"16749033974285927585"}}},"cell_type":"code","source":["!pip install mxnet-cu92\n","!mkdir -p drive\n","!google-drive-ocamlfuse drive\n","\n","import os\n","os.chdir(os.path.join(os.getcwd(),'drive'))\n","print(os.getcwd())\n","print(os.listdir(os.getcwd()))"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: mxnet-cu92 in /usr/local/lib/python3.6/dist-packages (1.3.1)\n","Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from mxnet-cu92) (0.8.4)\n","Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.6/dist-packages (from mxnet-cu92) (2.21.0)\n","Requirement already satisfied: numpy<1.15.0,>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from mxnet-cu92) (1.14.6)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet-cu92) (1.22)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet-cu92) (2018.11.29)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet-cu92) (2.6)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet-cu92) (3.0.4)\n","fuse: mountpoint is not empty\n","fuse: if you are sure this is safe, use the 'nonempty' mount option\n","/content/drive\n","['drive']\n"],"name":"stdout"}]},{"metadata":{"id":"II2pmQDQ2X1d","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":222},"outputId":"a22cf76a-db8e-4b03-c45b-51cd52f34ce8","executionInfo":{"status":"error","timestamp":1550111894247,"user_tz":-480,"elapsed":3524,"user":{"displayName":"binghao liang","photoUrl":"","userId":"16749033974285927585"}}},"cell_type":"code","source":["!ls\n","os.chdir('d2l-zh')\n","!ls"],"execution_count":5,"outputs":[{"output_type":"stream","text":["drive\n"],"name":"stdout"},{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-91f9275fe707>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ls'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'd2l-zh'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ls'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'd2l-zh'"]}]},{"metadata":{"id":"NbIofCts2MJw","colab_type":"code","colab":{}},"cell_type":"code","source":["import d2lzh as d2l\n","import mxnet as mx\n","from mxnet import autograd, gluon, init, nd\n","from mxnet.gluon import loss as gloss, nn\n","import time\n","\n","net = nn.Sequential()\n","net.add(nn.Conv2D(channels=6, kernel_size=5, activation='sigmoid'),\n","        nn.MaxPool2D(pool_size=2, strides=2),\n","        nn.Conv2D(channels=16, kernel_size=5, activation='sigmoid'),\n","        nn.MaxPool2D(pool_size=2, strides=2),\n","        # Dense会默认将(批量大小,通道,高,宽)形状的输入转换成(批量大小,通道 * 高 * 宽)形\n","        # 状的输入\n","        nn.Dense(120, activation='sigmoid'),\n","        nn.Dense(84, activation='sigmoid'),\n","        nn.Dense(10))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"4Wf0lN4F2MJ0","colab_type":"text"},"cell_type":"markdown","source":["接下来我们构造一个高和宽均为28的单通道数据样本，并逐层进行前向计算来查看每个层的输出形状。"]},{"metadata":{"id":"4fFtpC__2MJ1","colab_type":"code","colab":{},"outputId":"604db68c-a6a9-4ff3-c9c1-3e5709193547"},"cell_type":"code","source":["X = nd.random.uniform(shape=(1, 1, 28, 28))\n","net.initialize()\n","for layer in net:\n","    X = layer(X)\n","    print(layer.name, 'output shape:\\t', X.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["conv2 output shape:\t (1, 6, 24, 24)\n","pool2 output shape:\t (1, 6, 12, 12)\n","conv3 output shape:\t (1, 16, 8, 8)\n","pool3 output shape:\t (1, 16, 4, 4)\n","dense3 output shape:\t (1, 120)\n","dense4 output shape:\t (1, 84)\n","dense5 output shape:\t (1, 10)\n"],"name":"stdout"}]},{"metadata":{"id":"bInJm1dF2MJ8","colab_type":"text"},"cell_type":"markdown","source":["可以看到在卷积层块中输入的高和宽在逐层减小。卷积层由于使用高和宽均为5的卷积核，从而将高和宽分别减小4，而池化层则将高和宽减半，但通道数则从1增加到16。全连接层则逐层减少输出个数，直到变成图像的类别数10。\n","\n","\n","## 获取数据和训练\n","\n","下面我们来实验LeNet模型。实验中，我们仍然使用Fashion-MNIST作为训练数据集。"]},{"metadata":{"id":"7Sufv1yH2MJ9","colab_type":"code","colab":{}},"cell_type":"code","source":["batch_size = 256\n","train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size=batch_size)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"m9b279Xg2MKB","colab_type":"text"},"cell_type":"markdown","source":["因为卷积神经网络计算比多层感知机要复杂，建议使用GPU来加速计算。我们尝试在`gpu(0)`上创建NDArray，如果成功则使用`gpu(0)`，否则仍然使用CPU。"]},{"metadata":{"id":"ru6-VMw02MKC","colab_type":"code","colab":{},"outputId":"267447d9-e48d-4d0a-f0b7-a6e22c64d3dd"},"cell_type":"code","source":["def try_gpu():  # 本函数已保存在d2lzh包中方便以后使用\n","    try:\n","        ctx = mx.gpu()\n","        _ = nd.zeros((1,), ctx=ctx)\n","    except mx.base.MXNetError:\n","        ctx = mx.cpu()\n","    return ctx\n","\n","ctx = try_gpu()\n","ctx"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["cpu(0)"]},"metadata":{"tags":[]},"execution_count":7}]},{"metadata":{"id":"JEhWAtNW2MKG","colab_type":"text"},"cell_type":"markdown","source":["相应地，我们对[“Softmax回归的从零开始实现”](../chapter_deep-learning-basics/softmax-regression-scratch.md)一节中描述的`evaluate_accuracy`函数略作修改。由于数据刚开始存在CPU使用的内存上，当`ctx`变量代表GPU及相应的显存时，我们通过[“GPU计算”](../chapter_deep-learning-computation/use-gpu.md)一节中介绍的`as_in_context`函数将数据复制到显存上，例如`gpu(0)`。"]},{"metadata":{"id":"POacgphh2MKH","colab_type":"code","colab":{}},"cell_type":"code","source":["# 本函数已保存在d2lzh包中方便以后使用。该函数将被逐步改进：它的完整实现将在“图像增广”一节中\n","# 描述\n","def evaluate_accuracy(data_iter, net, ctx):\n","    acc_sum, n = nd.array([0], ctx=ctx), 0\n","    for X, y in data_iter:\n","        # 如果ctx代表GPU及相应的显存，将数据复制到显存上\n","        X, y = X.as_in_context(ctx), y.as_in_context(ctx).astype('float32')\n","        acc_sum += (net(X).argmax(axis=1) == y).sum()\n","        n += y.size\n","    return acc_sum.asscalar() / n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"wn8l9D8w2MKK","colab_type":"text"},"cell_type":"markdown","source":["我们同样对[“Softmax回归的从零开始实现”](../chapter_deep-learning-basics/softmax-regression-scratch.md)一节中定义的`train_ch3`函数略作修改，确保计算使用的数据和模型同在内存或显存上。"]},{"metadata":{"id":"n8iTsALU2MKL","colab_type":"code","colab":{}},"cell_type":"code","source":["# 本函数已保存在d2lzh包中方便以后使用\n","def train_ch5(net, train_iter, test_iter, batch_size, trainer, ctx,\n","              num_epochs):\n","    print('training on', ctx)\n","    loss = gloss.SoftmaxCrossEntropyLoss()\n","    for epoch in range(num_epochs):\n","        train_l_sum, train_acc_sum, n, start = 0.0, 0.0, 0, time.time()\n","        for X, y in train_iter:\n","            X, y = X.as_in_context(ctx), y.as_in_context(ctx)\n","            with autograd.record():\n","                y_hat = net(X)\n","                l = loss(y_hat, y).sum()\n","            l.backward()\n","            trainer.step(batch_size)\n","            y = y.astype('float32')\n","            train_l_sum += l.asscalar()\n","            train_acc_sum += (y_hat.argmax(axis=1) == y).sum().asscalar()\n","            n += y.size\n","        test_acc = evaluate_accuracy(test_iter, net, ctx)\n","        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, '\n","              'time %.1f sec'\n","              % (epoch + 1, train_l_sum / n, train_acc_sum / n, test_acc,\n","                 time.time() - start))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"SH2GMk8a2MKP","colab_type":"text"},"cell_type":"markdown","source":["我们重新将模型参数初始化到设备变量`ctx`之上，并使用Xavier随机初始化。损失函数和训练算法则依然使用交叉熵损失函数和小批量随机梯度下降。"]},{"metadata":{"id":"-m7e8LHs2MKQ","colab_type":"code","colab":{},"outputId":"8ae95921-acae-4243-8155-6d86670ab2dd"},"cell_type":"code","source":["lr, num_epochs = 0.9, 5\n","net.initialize(force_reinit=True, ctx=ctx, init=init.Xavier())\n","trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': lr})\n","train_ch5(net, train_iter, test_iter, batch_size, trainer, ctx, num_epochs)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["training on cpu(0)\n","epoch 1, loss 2.3198, train acc 0.101, test acc 0.100, time 27.9 sec\n","epoch 2, loss 1.9623, train acc 0.245, test acc 0.569, time 27.2 sec\n","epoch 3, loss 0.9663, train acc 0.615, test acc 0.688, time 26.9 sec\n","epoch 4, loss 0.7626, train acc 0.704, test acc 0.731, time 26.8 sec\n"],"name":"stdout"}]},{"metadata":{"id":"xVJ_tLyd2MKU","colab_type":"text"},"cell_type":"markdown","source":["## 小结\n","\n","* 卷积神经网络就是含卷积层的网络。\n","* LeNet交替使用卷积层和最大池化层后接全连接层来进行图像分类。\n","\n","## 练习\n","\n","* 尝试基于LeNet构造更复杂的网络来改善精度。例如，调整卷积窗口大小、输出通道数、激活函数和全连接层输出个数。在优化方面，可以尝试使用不同的学习率、初始化方法以及增加迭代周期。\n","\n","\n","## 扫码直达[讨论区](https://discuss.gluon.ai/t/topic/737)\n","\n","![](../img/qr_lenet.svg)\n","\n","## 参考文献\n","\n","[1] LeCun, Y., Bottou, L., Bengio, Y., & Haffner, P. (1998). Gradient-based learning applied to document recognition. Proceedings of the IEEE, 86(11), 2278-2324."]}]}